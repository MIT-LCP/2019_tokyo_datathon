{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-prediction",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIT-LCP/2019_tokyo_datathon/blob/master/04_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T3wdKZCPklNq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# eICU Collaborative Research Database\n",
        "\n",
        "# Notebook 4: Prediction\n",
        "\n",
        "This notebook explores how a decision trees can be trained to predict in-hospital mortality of patients.\n"
      ]
    },
    {
      "metadata": {
        "id": "rG3HrM7GkwCH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load libraries and connect to the database"
      ]
    },
    {
      "metadata": {
        "id": "s-MoFA6NkkbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.path as path\n",
        "\n",
        "# model building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn import impute\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Make pandas dataframes prettier\n",
        "from IPython.display import display, HTML, Image\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Access data using Google BigQuery.\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyBV_Q9DkyD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# authenticate\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cF1udJKhkzYq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up environment variables\n",
        "project_id='datathonjapan2019'\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"]=project_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xGurBAQIUDTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To make our lives easier, we'll also install and import a set of helper functions from the `datathon2` package. We will be using the following functions from the package:\n",
        "- `plot_model_pred_2d`: to visualize our data, helping to display a class split assigned by a tree vs the true class.\n",
        "- `run_query()`: to run an SQL query against our BigQuery database and assign the results to a dataframe. \n"
      ]
    },
    {
      "metadata": {
        "id": "GDEewAlvk0oT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install datathon2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JM6O5GPAUI89",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datathon2 as dtn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hq_09Hh-y17k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we'll be looking at tree models, so we'll now install and import packages for visualizing these models."
      ]
    },
    {
      "metadata": {
        "id": "jBMOwgwszGOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install graphviz -y\n",
        "!pip install pydotplus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jQmSKVhzRMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pydotplus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgcRCqxCk3HC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the patient cohort\n",
        "\n",
        "In this example, we will load all data from the patient data, and link it to physiology score data to provide richer summary information. Note that physiology score measurements indicate the \"worst\" value during the first day."
      ]
    },
    {
      "metadata": {
        "id": "ReCl7-aek1-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Link the patient, apachepatientresult, and apacheapsvar tables on patientunitstayid\n",
        "# using an inner join.\n",
        "query = \"\"\"\n",
        "SELECT p.unitadmitsource, p.gender, p.age, p.unittype, p.unitstaytype, \n",
        "    a.actualhospitalmortality,\n",
        "    v.heartrate, v.meanbp\n",
        "FROM `physionet-data.eicu_crd_demo.patient` p\n",
        "INNER JOIN `physionet-data.eicu_crd_demo.apachepatientresult` a\n",
        "ON p.patientunitstayid = a.patientunitstayid\n",
        "INNER JOIN `physionet-data.eicu_crd_demo.apacheapsvar` v\n",
        "ON p.patientunitstayid = v.patientunitstayid\n",
        "WHERE a.apacheversion LIKE 'IVa'\n",
        "\"\"\"\n",
        "\n",
        "cohort = dtn.run_query(query,project_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yxLctVBpk9sO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cohort.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPlwRV2buYb1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for analysis\n",
        "\n",
        "Before continuing, we want to review our data, paying attention to factors such as:\n",
        "- data types (for example, are values recorded as characters or numerical values?) \n",
        "- missing data\n",
        "- distribution of values"
      ]
    },
    {
      "metadata": {
        "id": "v3OJ4LDvueKu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# review the data dataset\n",
        "print(cohort.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4wQ6o_RvLph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encode the categorical data\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "cohort['gender_code'] = encoder.fit_transform(cohort['gender'])\n",
        "cohort['unittype_code'] = encoder.fit_transform(cohort['unittype'])\n",
        "cohort['actualhospitalmortality_code'] = encoder.fit_transform(cohort['actualhospitalmortality'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ogi_ns-ylnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Handle the deidentified ages\n",
        "cohort['agenum'] = pd.to_numeric(cohort['age'], downcast='integer', errors='coerce')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77M0QJQ5wcPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preview the encoded data\n",
        "cohort[['gender','gender_code']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GqvwTNPN3KZz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check the outcome variable\n",
        "cohort['actualhospitalmortality_code'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ze7y5J4Ioz8u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create our train and test sets\n",
        "\n",
        "Note that we only use two columns of data because initially we'd like to visualize our tree models in two dimensions. "
      ]
    },
    {
      "metadata": {
        "id": "i5zXkn_AlDJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = ['heartrate','meanbp']\n",
        "outcome = 'actualhospitalmortality_code'\n",
        "\n",
        "X = cohort[features]\n",
        "y = cohort[outcome]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IHhIgDUwocmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvQWkuY6nkZ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Review the number of cases in each set\n",
        "print(\"Train data: {}\".format(len(X_train)))\n",
        "print(\"Test data: {}\".format(len(X_test)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2waK5qBqanC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decision trees\n",
        "\n",
        "Let's build the simplest tree model we can think of: a classification tree with only one split. Decision trees of this form are commonly referred to under the umbrella term Classification and Regression Trees (CART) [1]. While we will only be looking at classification here, regression isn't too different. After grouping the data (which is essentially what a decision tree does), classification involves assigning all members of the group to the majority class of that group during training. Regression is the same, except you would assign the average value, not the majority. In the case of a decision tree with one split, often called a \"stump\", the model will partition the data into two groups, and assign classes for those two groups based on majority vote. There are many parameters available for the DecisionTreeClassifier class; by specifying max_depth=1 we will build a decision tree with only one split - i.e. of depth 1.\n",
        "\n",
        "[1] L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984."
      ]
    },
    {
      "metadata": {
        "id": "RlG3N3OYBqAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# specify max_depth=1 so we train a stump, i.e. a tree with only 1 split\n",
        "mdl = tree.DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# fit the model to the data - trying to predict y from X\n",
        "mdl = mdl.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8RlioUw8B_0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since our model is so simple, we can actually look at the full decision tree."
      ]
    },
    {
      "metadata": {
        "id": "G2t9Nz8pBqEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "graph = dtn.create_graph(mdl,feature_names=features)\n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-iPwWWKCGY9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we see three nodes: a node at the top, a node in the lower left, and a node in the lower right.\n",
        "\n",
        "The top node is the root of the tree: it contains all the data. Let's read this node bottom to top:\n",
        "- `value = [809, 78]`:  Current class balance. There are 809 observations of class 1 and 78 observations of class 2.\n",
        "- `samples = 887`:  Number of samples assessed at this node.\n",
        "- `gini = 0.16`: Gini impurity, a measure of \"impurity\". The higher the value, the bigger the mix of classes. A 50/50 split of two classes would result in an index of 0.5.\n",
        "- `meanbp <=46.5`: Decision rule learned by the node. In this case, patients with a mean BP of <= 46.5 are moved into the left node and >46.5 to the right. "
      ]
    },
    {
      "metadata": {
        "id": "KS0UcZqUeJKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The gini impurity is is actually used by the algorithm to determine a split. The model evaluates every feature (in our case, heart rate and blood pressure) at every possible split (46, 47..) to find the split that has the lowest gini impurity in two resulting nodes. \n",
        "\n",
        "The approach is referred to as \"greedy\", because we are choosing the optimal split given our current state. Let's take a closer look at our decision boundary."
      ]
    },
    {
      "metadata": {
        "id": "uXl22sNTtpHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# look at the regions in a 2d plot\n",
        "# based on scikit-learn tutorial plot_iris.html\n",
        "plt.figure(figsize=[10,8])\n",
        "dtn.plot_model_pred_2d(mdl, X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25zSX-inCNOJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this plot we can see the decision boundary on the y-axis, separating the predicted classes. The true classes are indicated at each point. Where the background and point colours are mismatched, there has been misclassification. Of course we are using a very simple model. Let's see what happens when we increase the depth to 5."
      ]
    },
    {
      "metadata": {
        "id": "ZuO62CL3CSGm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdl = tree.DecisionTreeClassifier(max_depth=5)\n",
        "mdl = mdl.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A88Vi83LCSJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10,8])\n",
        "dtn.plot_model_pred_2d(mdl, X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B88XlKDtCYmn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now our tree is more complicated! We can see a few vertical boundaries as well as the horizontal one from before. Some of these we may like, but some appear unnatural. Let's look at the tree itself."
      ]
    },
    {
      "metadata": {
        "id": "V1VLrOJJCcWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
        "                         feature_names=feat, \n",
        "                         filled=True, rounded=True)  \n",
        "graph = pydotplus.graphviz.graph_from_dot_data(tree_graph) \n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvsNIjCDDIo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}